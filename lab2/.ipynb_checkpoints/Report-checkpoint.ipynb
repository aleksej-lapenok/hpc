{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOAL OF LABORATORY WORK\n",
    "Using the trapezoidal rule of definite integral to approximate the regions or\n",
    "compartmentalized sections under a graph of a given function and also calculating the area as\n",
    "well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK DEFINITION\n",
    "The specific problem that is solved in the laboratory work (1 paragraph).\n",
    "Calculating the execution time of a serial program, that is, the estimated time required for calculating the values of different upper and lower bounds of an integral, which is given as follows:\n",
    "\n",
    "\n",
    "Choosing an arbitrary value of epsilon, with a maximum value of 10^-7. Convert the serial program written to a parallel program using OpenMP by using reduction concept and\n",
    "synchronization methods, such as; lock, atomic and critical sections. Later, count the speedup of executions based on different thread numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BRIEF THEORY\n",
    "OpenMP (Open Multi-Processing) is an application programming interface (API) that\n",
    "supports multi-platform shared memory multiprocessing programming in C, C++, and Fortran on most platforms, instruction set architectures and operating systems, including Solaris, AIX, HP-UX, Linux, macOS, and Windows. It consists of a set of compiler directives, library routines, and environment variables that influence run-time behaviorAn application built with the hybrid model of parallel programming can run on a computer cluster using both OpenMP and Message Passing Interface (MPI), such that OpenMP is used for parallelism within a (multi-core) node while MPI is used for parallelism between nodes. There have also been efforts to run OpenMP on software distributed shared memory systems, to translate OpenMP into MPI and to extend OpenMP for non-shared memory systems.\n",
    "\n",
    "Synchronization Methods in OpenMP.\n",
    "To control issues pertaining to race conditions, synchronization methods are used to\n",
    "protect data conflicts.\n",
    "\n",
    "- Reduction – reduction clause: reduction(op:list). A local copy of each list of variable is made and initialized depending on the op. Example; 1 for ‘*’, the sign is assigned to number 1 as its identity. Updates occur on the local copy, then reduced into a single value and combined with the original global value. The construct for reduction is combined with the for construct: #pragma omp parallel for reduction(+:plus)\n",
    "- Critical – allows on thread of code execute at a time. If a thread is performing a computation and hits a critical section in a block which isn’t free, it has to wait for its turn. When a thread finishes its computation, it releases for the next thread in queue. The construct for critical section is #pragma omp critical; and it consumes all executions do by individual threads every time, i.e. on every overhead.\n",
    "- Lock – is the lowest level of mutual exclusion synchronization; Lock Routines: omp_init_lock(), omp_set_lock(), omp_unset_lock(), omp_destroy_lock(), and omp_test_lock. Setting locks on essential section of codes in parallel for a thread at a time. Memory is released for the next thread when it has completed it task. Sometimes, with the help of omp_test_lock(), it queries to find free threads.\n",
    "- Atomic – allows for quick updates of values in memory. It applies to a simple binary operation when updating a value. Example of its use is during an increment, decrement or performing operations such as read or write. The construct for atomic section is #pragma omp atomic. \n",
    "\n",
    "## Trapezoidal Rule\n",
    "The trapezoidal rule is a technique for approximating the definite integral by approximating the region under the graph of the function as a trapezoid and calculating its area. Most often used in numerical analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALGORITHM (METHOD) OF IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <omp.h>\r\n",
      "\r\n",
      "#include <stdio.h>\r\n",
      "#include <stdlib.h> \r\n",
      "\r\n",
      "\r\n",
      "// #include <boost/math/quadrature/trapezoidal.hpp>\r\n",
      "\r\n",
      "#define A ((double)_A)\r\n",
      "#define B ((double)_B)\r\n",
      "#define N ((double)_N)\r\n",
      "#define PREC ((double)_PREC)\r\n",
      "\r\n",
      "\r\n",
      "#ifndef INTEG\r\n",
      "# define INTEG integrate0\r\n",
      "#endif\r\n",
      "\r\n",
      "\r\n",
      "#ifndef COMPUTE_SUM\r\n",
      "# define COMPUTE_SUM compute_sum_reduction\r\n",
      "#endif\r\n",
      "\r\n",
      "#include <math.h>\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "double f(double x) {\r\n",
      "\tdouble a = (1./x) * sin(1./x);\r\n",
      "\treturn pow(a, 2);\r\n",
      "}\r\n",
      "\r\n",
      "double f_int(double a, double b) {\r\n",
      "\treturn (1./4.) * (  2. * (b-a)/(a*b) + sin(2/b) - sin(2/a) );\r\n",
      "}\r\n",
      "\r\n",
      "double F(double x) {\r\n",
      "\treturn -1/(2*x) + (1/4) * sin(2/x);\r\n",
      "}\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "double compute_sum_raw(size_t p, double h, double a){\r\n",
      "\tdouble sum = 0;\r\n",
      "\r\n",
      "\t// #pragma omp parallel for\r\n",
      "\tfor(size_t j = 1; j < p; j += 1)\r\n",
      "\t{\r\n",
      "\t\tdouble y = f(a + j*h);\r\n",
      "\t\tsum += y;\r\n",
      "\t}\r\n",
      "\treturn sum;\r\n",
      "}\r\n",
      "\r\n",
      "double compute_sum_atomic(size_t p, double h, double a){\r\n",
      "\tdouble sum = 0;\r\n",
      "\r\n",
      "\t#pragma omp parallel for\r\n",
      "\tfor(size_t j = 1; j < p; j += 1)\r\n",
      "\t{\r\n",
      "\t\tdouble y = f(a + j*h);\r\n",
      "\t\t#pragma omp atomic\r\n",
      "\t\tsum += y;\r\n",
      "\t}\r\n",
      "\treturn sum;\r\n",
      "}\r\n",
      "\r\n",
      "double compute_sum_critical(size_t p, double h, double a){\r\n",
      "\tdouble sum = 0;\r\n",
      "\r\n",
      "\t#pragma omp parallel for\r\n",
      "\tfor(size_t j = 1; j < p; j += 1)\r\n",
      "\t{\r\n",
      "\t\tdouble y = f(a + j*h);\r\n",
      "\t\t#pragma omp critical\r\n",
      "\t\tsum += y;\r\n",
      "\t}\r\n",
      "\treturn sum;\r\n",
      "}\r\n",
      "\r\n",
      "double compute_sum_reduction(size_t p, double h, double a){\r\n",
      "\tdouble sum = 0;\r\n",
      "\r\n",
      "\t#pragma omp parallel for reduction(+:sum)\r\n",
      "\tfor(size_t j = 1; j < p; j += 1)\r\n",
      "\t{\r\n",
      "\t\tdouble y = f(a + j*h);\r\n",
      "\t\tsum += y;\r\n",
      "\t}\r\n",
      "\treturn sum;\r\n",
      "}\r\n",
      "\r\n",
      "double compute_sum_locks(size_t p, double h, double a){\r\n",
      "\tdouble sum = 0;\r\n",
      "\tomp_lock_t lock;\r\n",
      "\r\n",
      "\tomp_init_lock(&lock);\r\n",
      "\r\n",
      "\t#pragma omp parallel for\r\n",
      "\tfor(size_t j = 1; j < p ; j += 1)\r\n",
      "\t{\r\n",
      "\t\tdouble y = f(a + j*h);\r\n",
      "\r\n",
      "\t\tomp_set_lock(&lock);\r\n",
      "\t\tsum += y;\r\n",
      "\t\tomp_unset_lock(&lock);\r\n",
      "\t}\r\n",
      "\tomp_destroy_lock(&lock);\r\n",
      "\r\n",
      "\treturn sum;\r\n",
      "}\r\n",
      "\r\n",
      "\r\n",
      "#define compute_sum compute_sum_atomic\r\n",
      "\r\n",
      "\r\n",
      "double integrate0() {\r\n",
      "\tdouble a = A, b = B;\r\n",
      "    double ya = f(a), yb = f(b);\r\n",
      "    double h, error;\r\n",
      "    double sum1 = 0, sum2 = 0, sum;\r\n",
      "\r\n",
      "    int n = 4;\r\n",
      "\r\n",
      "    for(size_t i = 0; i < 1e6; i += 50) {\r\n",
      "    \t\r\n",
      "\r\n",
      "    \tn += 1;\r\n",
      "    \th = (b - a)/n;\r\n",
      "\r\n",
      "    \tsum = (ya + yb)*0.5;\r\n",
      "    \tsum += COMPUTE_SUM(n, h, a);\r\n",
      "    \tsum *= h;\r\n",
      "\r\n",
      "\t\tsum1 = sum2;\r\n",
      "\t\tsum2 = sum;\r\n",
      "    \tif(i != 0) {\r\n",
      "    \t\terror = fabs(sum2-sum1)/fabs(sum2);\r\n",
      "    \t\tif(fabs(error) <= fabs(PREC)) {\r\n",
      "\t    \t\tbreak;\r\n",
      "    \t\t}\r\n",
      "    \t}\r\n",
      "    }\r\n",
      "    \r\n",
      "    printf(\"points: %d\\n\", n);\r\n",
      "    return sum2;\r\n",
      "}\r\n",
      "\r\n",
      "double integrate1() {\r\n",
      "\tdouble a = A, b = B;\r\n",
      "    double ya = f(a), yb = f(b);\r\n",
      "    double h, error;\r\n",
      "    double sum1 = 0, sum_res = 0;\r\n",
      "    double *sums, sum;\r\n",
      "    int n = 4, end_work = 0;\r\n",
      "\r\n",
      "    #pragma omp parallel shared(n, sums, sum, end_work, sum_res)\r\n",
      "    {\r\n",
      "    \tint tid = omp_get_thread_num();\r\n",
      "    \tint n_threads = omp_get_num_threads();\r\n",
      "\r\n",
      "\r\n",
      "    \t#pragma omp single\r\n",
      "    \t{\r\n",
      "    \t\tsums = (double*)malloc(n_threads * sizeof(double));\r\n",
      "    \t}\r\n",
      "\r\n",
      "    \t// #pragma omp barrier\r\n",
      "\r\n",
      "\r\n",
      "\t    for(size_t i = 0; i < 1e6; ++i, n += n_threads) {\r\n",
      "    \t\tint __end_work;\r\n",
      "\t    \tint _n = n + tid;\r\n",
      "\t    \t\r\n",
      "\t    \tdouble h = (b - a)/_n;\r\n",
      "\r\n",
      "\t    \tsums[tid] = (ya + yb)*0.5;\r\n",
      "\r\n",
      "\t\t\t// #pragma omp for reduction(+:sum) nowait\r\n",
      "\t\t\t#pragma omp taskloop nowait\r\n",
      "\t\t\t\tfor(size_t j = 1; j < _n; j += 1) {\r\n",
      "\t\t\t\t\tsums[tid] += f(a + j*h);\r\n",
      "\t\t\t\t}\r\n",
      "\t    \tsums[tid] *= h;\r\n",
      "\r\n",
      "\r\n",
      "\t    \t#pragma omp barrier\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\t    \t#pragma omp single\r\n",
      "    \t\t{\r\n",
      "\t\t    \tfor(size_t j = 1; j < n_threads; ++j) {\r\n",
      "\t\t    \t\terror = fabs(sums[j-1] - sums[j])/fabs(sums[j]);\r\n",
      "\t\t    \t\t// printf(\"%d %.9lf\\n\", tid, error);\r\n",
      "\t\t    \t\tif(fabs(error) <= fabs(PREC)) {\r\n",
      "\t\t    \t\t\t// printf(\"DONE\\n\");\r\n",
      "\r\n",
      "\t\t    \t\t\t#pragma omp atomic write\r\n",
      "\t\t    \t\t\t\tend_work = 1;\r\n",
      "\r\n",
      "\t\t    \t\t\tsum_res = sums[j];\r\n",
      "\t\t    \t\t\tbreak;\r\n",
      "\t    \t\t\t}\r\n",
      "\t\t    \t}\r\n",
      "\t\t    }\r\n",
      "\t\t    // #pragma omp barrier\r\n",
      "\r\n",
      "\r\n",
      "    \t\t#pragma omp atomic read\r\n",
      "\t\t\t\t__end_work = end_work;\r\n",
      "    \t\tif(__end_work) break;\r\n",
      "    \t\t\r\n",
      "\t    }\r\n",
      "\r\n",
      "    }\r\n",
      "    printf(\"points: %d\\n\", n);\r\n",
      "    return sum_res;\r\n",
      "}\r\n",
      "\r\n",
      "\r\n",
      "// double integrate_boost(int max_refinements, double tol) {\r\n",
      "// \tdouble a = A, b = B;\r\n",
      "//     double ya = f(a), yb = f(b);\r\n",
      "//     double h = (b - a)*0.5;\r\n",
      "//     double I0 = (ya + yb)*h;\r\n",
      "//     double IL0 = (abs(ya) + abs(yb))*h;\r\n",
      "\r\n",
      "//     double yh = f(a + h);\r\n",
      "//     double I1;\r\n",
      "//     I1 = I0*0.5 + yh*h;\r\n",
      "\r\n",
      "//     // The recursion is:\r\n",
      "//     // I_k = 1/2 I_{k-1} + 1/2^k \\sum_{j=1; j odd, j < 2^k} f(a + j(b-a)/2^k)\r\n",
      "//     size_t k = 2;\r\n",
      "//     // We want to go through at least 4 levels so we have sampled the function at least 10 times.\r\n",
      "//     // Otherwise, we could terminate prematurely and miss essential features.\r\n",
      "//     // This is of course possible anyway, but 10 samples seems to be a reasonable compromise.\r\n",
      "//     double error = abs(I0 - I1);\r\n",
      "//     int points = 0;\r\n",
      "//     while (k < 4 || (k < max_refinements && error > tol*abs(I1)) )\r\n",
      "//     {\r\n",
      "//         I0 = I1;\r\n",
      "\r\n",
      "//         I1 = I0*0.5;\r\n",
      "//         size_t p = static_cast<size_t>(1u) << k;\r\n",
      "//         points += p/2;\r\n",
      "//         h *= 0.5;\r\n",
      "\r\n",
      "//         double sum = COMPUTE_SUM(h, p, a);\r\n",
      "   \r\n",
      "//         I1 += sum*h;\r\n",
      "//         ++k;\r\n",
      "//         error = abs(I0 - I1);\r\n",
      "//     }\r\n",
      "//     printf(\"points: %d\\n\", points);\r\n",
      "//     return I1;\r\n",
      "// }\r\n",
      "\r\n",
      "\r\n",
      "int main(int argc, char *argv[]) \r\n",
      "{\r\n",
      "\r\n",
      "\tdouble sum = INTEG();\r\n",
      "\r\n",
      "\t// using boost::math::quadrature::trapezoidal;\r\n",
      "\t// double I = trapezoidal(f, A, B, boost::math::tools::root_epsilon<double>(), 10);\r\n",
      "\r\n",
      "\tprintf(\"res_prec: %f\\n\", f_int(A, B));\r\n",
      "\tprintf(\"res_prec2: %f\\n\",F(B)-F(A));\r\n",
      "\tprintf(\"res: %f\\n\", sum);\r\n",
      "\t// printf(\"res_boost: %f\\n\", I);\r\n",
      "\t// printf(\"precision: %f\\n\", fabs(sum - res_prec) / fabs(res_prec));\r\n",
      "\r\n",
      "\treturn 0;\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "%cat int.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULT AND EXPERIMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task:\n",
    "    \n",
    "1. Choose precision ε\n",
    "2. Calculate integral with different A and B values from the table\n",
    "3. Calculate execution time of serial program\n",
    "4. Write a parallel program with:\n",
    "    1. atomic\n",
    "    2. Critical sections\n",
    "    3. Locks\n",
    "    4. reduction\n",
    "5. Count speedup with different thread number\n",
    "6. Fill the table (for each point of 4a-4d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "\n",
    "def compile(*defs, **defskw):\n",
    "    args = [f\"-D{k}\" for k in defs] + [f\"-D{k}={v}\" for k, v in defskw.items()]\n",
    "    _cmd = 'g++ int.c -o int -fopenmp -lm -I boost_1_70_0/ -std=c++14'.split() + args\n",
    "    # print(' '.join(_cmd))\n",
    "    cmd = subprocess.run(_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "  \n",
    "    if(cmd.stdout): print('cmd.stdout', cmd.stdout)\n",
    "    if(cmd.stderr): print('cmd.stderr', cmd.stderr)\n",
    "    \n",
    "def run(env=None):\n",
    "    cmd = subprocess.run('./int', stdout=subprocess.PIPE, stderr=subprocess.PIPE, env=env)\n",
    "    return cmd.stdout.decode('utf8')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce  configuraions\n",
    "\n",
    "Lets test different reduce configuratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing integration with raw locking\n",
      "1.95 s ± 80.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Executing integration with atomic locking\n",
      "5.71 s ± 543 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Executing integration with locks locking\n",
      "11.5 s ± 1.41 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Executing integration with reduction locking\n",
      "693 ms ± 6.74 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Executing integration with critical locking\n",
      "8.66 s ± 172 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = os.environ.copy()\n",
    "env['OMP_NUM_THREADS'] = str(4)\n",
    "\n",
    "for x in ['raw', 'atomic', 'locks', 'reduction', 'critical']:\n",
    "    print(f'Executing integration with {x} locking')\n",
    "    compile(_A=1, _B=10, _PREC=-6.30E-11, COMPUTE_SUM=f'compute_sum_{x}')\n",
    "\n",
    "    %timeit run(env)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see the advatange of using OpenMP reductions.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread speedup\n",
    "\n",
    "Lets analyze how the number of threads affects the speed of the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing integration with 4 threads\n",
      "616 ms ± 86.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Executing integration with 2 threads\n",
      "1.08 s ± 60.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Executing integration with 1 threads (!!)\n",
      "1.92 s ± 24.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "env = os.environ.copy()\n",
    "env['OMP_NUM_THREADS'] = str(4)\n",
    "\n",
    "\n",
    "compile(_A=1, _B=10, _PREC=-6.30E-11, COMPUTE_SUM=f'compute_sum_reduction')\n",
    "\n",
    "print(f'Executing integration with 4 threads')\n",
    "%timeit run(env)\n",
    "\n",
    "env = os.environ.copy()\n",
    "env['OMP_NUM_THREADS'] = str(2)\n",
    "\n",
    "\n",
    "compile(_A=1, _B=10, _PREC=-6.30E-11, COMPUTE_SUM=f'compute_sum_reduction')\n",
    "\n",
    "print(f'Executing integration with 2 threads')\n",
    "%timeit run(env)\n",
    "\n",
    "env = os.environ.copy()\n",
    "env['OMP_NUM_THREADS'] = str(1)\n",
    "\n",
    "print(f'Executing integration with 1 threads (!!)')\n",
    "compile(_A=1, _B=10, _PREC=-6.30E-11, COMPUTE_SUM=f'compute_sum_reduction')\n",
    "\n",
    "%timeit run(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More threads equal to a faster execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative integration implementaion\n",
    "\n",
    "The program offered several ways to impove beyond the ordinary sum. An alternative version was also developed. In order to increase performance a combination of OpenMP task and OpenMP normal multithreading was used. No because of the design no reductions were possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative tasks based integration with 2 threas\n",
      "946 ms ± 69.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Default tasks based integration with 2 threas\n",
      "1.12 s ± 83.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Alternative tasks based integration with 4 threas\n",
      "456 ms ± 127 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Default tasks based integration with 4 threas\n",
      "652 ms ± 51.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Alternative tasks based integration with 8 threas\n",
      "286 ms ± 19.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Default tasks based integration with 8 threas\n",
      "670 ms ± 207 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Alternative tasks based integration with 16 threas\n",
      "101 ms ± 8.26 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Default tasks based integration with 16 threas\n",
      "1.92 s ± 230 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Alternative tasks based integration with 32 threas\n",
      "96.7 ms ± 24.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Default tasks based integration with 32 threas\n",
      "2.67 s ± 396 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ts in [2, 4,8, 16, 32]:\n",
    "    env = os.environ.copy()\n",
    "    env['OMP_NUM_THREADS'] = str(ts)\n",
    "    \n",
    "    compile(_A=1, _B=10, _PREC=-6.30E-11, INTEG='integrate1')\n",
    "    \n",
    "    print(f\"Alternative tasks based integration with {ts} threas\")\n",
    "    %timeit run(env)\n",
    "    \n",
    "    compile(_A=1, _B=10, _PREC=-6.30E-11, INTEG='integrate0')\n",
    "    \n",
    "    print(f\"Default tasks based integration with {ts} threas\")\n",
    "    %timeit run(env)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see the advantage of the task based design which maximize resource utilization without compromizing flexiblity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling the data\n",
    "\n",
    "Lets collect the data required by the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intergating on (1e-05, 0.0001) interval with -2.77e-11 precision\n",
      "Time taken: 28.7 s ± 1.95 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "points: 353300\n",
      "\n",
      "Intergating on (0.0001, 0.001) interval with 1.9e-10 precision\n",
      "Time taken: 2.95 s ± 859 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "points: 100940\n",
      "\n",
      "Intergating on (0.001, 0.01) interval with 2.05e-11 precision\n",
      "Time taken: 3.29 s ± 448 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "points: 110924\n",
      "\n",
      "Intergating on (0.01, 0.1) interval with -2.22e-12 precision\n",
      "Time taken: 2.75 s ± 495 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "points: 104748\n",
      "\n",
      "Intergating on (0.1, 1) interval with 8.67e-11 precision\n",
      "Time taken: 200 ms ± 33.8 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "points: 14988\n",
      "\n",
      "Intergating on (1, 10) interval with -6e-11 precision\n",
      "Time taken: The slowest run took 7.48 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "135 ms ± 88.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "points: 12444\n",
      "\n",
      "Intergating on (10, 100) interval with -6.3e-11 precision\n",
      "Time taken: 152 ms ± 40 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "points: 13780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xs = [ \n",
    "    ( 0.00001 , 0.0001 , -2.77e-11),\n",
    "    (  0.0001 ,  0.001 ,   1.9e-10), \n",
    "    (   0.001 ,   0.01 ,  2.05E-11),\n",
    "    (    0.01 ,    0.1 , -2.22E-12),\n",
    "    (     0.1 ,      1 ,  8.67E-11),\n",
    "    (       1 ,     10 , -6.00E-11),\n",
    "    (      10 ,    100 , -6.30E-11)\n",
    "]\n",
    "for a, b, eps in xs:\n",
    "    compile(_A=a, _B=b, _PREC=eps, INTEG='integrate1')\n",
    "    print(f\"Intergating on ({a}, {b}) interval with {eps} precision\")\n",
    "    print(\"Time taken:\", end=' ')\n",
    "    %timeit run(env)\n",
    "    print(run().split('\\n')[0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION\n",
    "The three method (locks, atomics, critical sections) shows less performance because of spending\n",
    "a lot of time on synchronizing and blocks, while the operation of summing is very expensive. So\n",
    "most of time threads just waiting for another threads unlock (or store the new value in memory\n",
    "or send the sync signals). The reduction shows good boost up, as the stl version (but not so\n",
    "much)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
