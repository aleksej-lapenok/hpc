{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal of laboratory work\n",
    "The purpose of this work is to implement an algorithm for calculating the degree of closeness of objects described by a set of numerically expressed properties using CUDA technology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Definition\n",
    "We have a set of objects that can be described by sets of properties expressed numerically. In this task, it is necessary to calculate the degree of similarity of objects. As input parameters we have a matrix:\n",
    "\n",
    "![](images/CropperScreenshot_2019-06-21_21:35:23.png)\n",
    "\n",
    "It is necessary to calculate the distance between each possible pair of rows of the matrix.\n",
    "\n",
    "![](images/CropperScreenshot_2019-06-21_21:35:41.png)\n",
    "\n",
    "The paper assumes the implementation of this algorithm using the software-hardware architecture of parallel computing CUDA with global and shared memory. It is necessary to determine the kernel configuration and perform acceleration tests with various examples of input parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief Theory\n",
    "CUDA technology introduces a number of additional extensions for the C language, which are necessary for writing code for the GPU:\n",
    "1. Function specifiers that show how and where functions will be performed from;\n",
    "2. The variable specifiers that serve to indicate the type of memory used by the GPU;\n",
    "3. GPU kernel launch qualifiers;\n",
    "4. Built-in variables for identifying threads, blocks and other parameters when executing code in the GPU core.\n",
    "5. Additional types of variables.\n",
    "\n",
    "\n",
    "Function specifiers determine how and from where the functions will be called. There are 3 such specifiers in CUDA:\n",
    "- __host__ \n",
    "- __global__ \n",
    "- __device__ \n",
    "\n",
    "\n",
    "Kernel launch qualifiers are used to describe the number of blocks, threads, and memory that need to be allocated when calculating on a GPU. \n",
    "The CUDA host API is the link between the CPU and the GPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALGORITHM (METHOD) of IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <cuda_runtime.h>\r\n",
      "\r\n",
      "#include <iostream>\r\n",
      "#include <memory>\r\n",
      "#include <string>\r\n",
      "\r\n",
      "#include <cuda.h>\r\n",
      "#include <stdio.h>\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "#ifndef BLOCK_SIZE\r\n",
      "# define BLOCK_SIZE 16\r\n",
      "#endif\r\n",
      "\r\n",
      "#ifndef _M\r\n",
      "# define _M 10000\r\n",
      "#endif\r\n",
      "\r\n",
      "#ifndef _N\r\n",
      "# define _N 10000\r\n",
      "#endif\r\n",
      "\r\n",
      "#if !defined(CUDA) && !defined(CPU) && !defined(CHECK)\r\n",
      "# define CUDA\r\n",
      "#endif\r\n",
      "\r\n",
      "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\r\n",
      "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\r\n",
      "{\r\n",
      "   if (code != cudaSuccess) \r\n",
      "   {\r\n",
      "      fprintf(stderr,\"gpuAssert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\r\n",
      "      if (abort) exit(code);\r\n",
      "   }\r\n",
      "}\r\n",
      "\r\n",
      "__global__ void mx_dist(float *m_in, float *m_out, int m, int n) \r\n",
      "{\r\n",
      "    int i = blockIdx.y * blockDim.y + threadIdx.y; \r\n",
      "    int j = blockIdx.x * blockDim.x + threadIdx.x;\r\n",
      "\tfloat s = 0, sum = 0;\r\n",
      "\r\n",
      "    if( i < m && j < m) {\r\n",
      "\r\n",
      "    \tfor(int k = 0; k < n; ++k) {\r\n",
      "    \t\ts = m_in[i*m + k] - m_in[j*m + k];\r\n",
      "    \t\tsum += s*s;\r\n",
      "    \t}\r\n",
      "\r\n",
      "    \t// printf(\"--> %d %d %f %f\\n\", j, i, m_in[j*n], sum);\r\n",
      "    \tm_out[i*m + j] = sum;\r\n",
      "    }\r\n",
      "}\r\n",
      "\r\n",
      "void mx_dist_cpu(float *m_in, float *m_out, int m, int n) \r\n",
      "{ \r\n",
      "\tfloat s, sum;\r\n",
      "    \r\n",
      "\tfor(int i = 0; i < m; ++i) \r\n",
      "\t\tfor(int j = 0; j < m; ++j) {\r\n",
      "\t\t\tsum = 0;\r\n",
      "\t\t\tfor(int k = 0; k < n; ++k) {\r\n",
      "\t\t\t\ts = m_in[i*m + k] - m_in[j*m + k];\r\n",
      "\t\t\t\tsum += s*s;\r\n",
      "\t\t\t}\r\n",
      "\t\t\tm_out[i*m + j] = sum;\r\n",
      "\t\t}\r\n",
      "}\r\n",
      "\r\n",
      "void init_mx(float *A, size_t m, size_t n) \r\n",
      "{\r\n",
      "\tfor(int i = 0; i < m; ++i) {\t\t\r\n",
      "\t\tfor(int j = 0; j < n; ++j) {\r\n",
      "\t\t\tfloat t = sin(i*m + j) * 10 + 1; \r\n",
      "\t\t\tA[i*m + j] = t;\r\n",
      "\t\t}\r\n",
      "\t}\r\n",
      "}\r\n",
      "void print_mx(float *A, size_t m, size_t n) \r\n",
      "{\r\n",
      "\tfor(int i = 0; i < m; ++i) {\t\t\r\n",
      "\t\tfor(int j = 0; j < n; ++j) {\r\n",
      "\t\t\tprintf(\"%d %d %f\\n\", i, j, A[i*m + j]);\t\t\t\r\n",
      "\t\t}\r\n",
      "\t}\r\n",
      "}\r\n",
      "\r\n",
      "void cmp_mx(float *A, float *B, size_t m, size_t n) \r\n",
      "{\r\n",
      "\tfor(int i = 0; i < m; ++i) {\t\t\r\n",
      "\t\tfor(int j = 0; j < n; ++j) {\r\n",
      "\t\t\tif( abs(A[i*m + j] - B[i*m + j]) > 0.01) {\r\n",
      "\t\t\t\tprintf(\"not equal %f %f\\n\", A[i*m + j], B[i*m + j]);\r\n",
      "\t\t\t\treturn;\r\n",
      "\t\t\t} else {\r\n",
      "\t\t\t\tprintf(\"Equal\\n\");\r\n",
      "\t\t\t}\r\n",
      "\t\t}\r\n",
      "\t}\r\n",
      "}\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "float *run_cuda(float *A, size_t m, size_t n) \r\n",
      "{\r\n",
      "\tcudaError_t e;\r\n",
      "\r\n",
      "\tfloat *A_d;\r\n",
      "\tfloat *B, *B_d;\r\n",
      "\r\n",
      "\tB = (float*) malloc(m*m*sizeof(float));\r\n",
      "\r\n",
      "\r\n",
      "\te = cudaMalloc(&A_d, m*n*sizeof(float));\r\n",
      "\tgpuErrchk(e);\r\n",
      "\te = cudaMalloc(&B_d, m*m*sizeof(float));\r\n",
      "\tgpuErrchk(e);\r\n",
      "\r\n",
      "\r\n",
      "\te = cudaMemcpy(A_d, A, m*n*sizeof(float), \r\n",
      "\t\t\t\tcudaMemcpyHostToDevice);\r\n",
      "\tgpuErrchk(e);\t\r\n",
      "\r\n",
      "\r\n",
      "    unsigned int grid_rows = (m + BLOCK_SIZE - 1) / BLOCK_SIZE;\r\n",
      "    unsigned int grid_cols = (n + BLOCK_SIZE - 1) / BLOCK_SIZE;\r\n",
      "\r\n",
      "    dim3 dimGrid(grid_cols, grid_rows);\r\n",
      "    dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\r\n",
      "\r\n",
      "\tmx_dist<<<dimGrid, dimBlock>>>(A_d, B_d, m, n);\r\n",
      "\r\n",
      "\r\n",
      "\te = cudaMemcpy(B, B_d, m*m*sizeof(float), \r\n",
      "\t\t\t\tcudaMemcpyDeviceToHost);\r\n",
      "\tgpuErrchk(e);\r\n",
      "\r\n",
      "\r\n",
      "\tcudaFree(A_d);\r\n",
      "\tcudaFree(B_d);\r\n",
      "\r\n",
      "\t\r\n",
      "\treturn B;\r\n",
      "}\r\n",
      "\r\n",
      "\r\n",
      "float *run_cpu(float *A, size_t m, size_t n) \r\n",
      "{    \r\n",
      "\t\r\n",
      "\tfloat *B;\r\n",
      "\tB = (float*) malloc(m*m*sizeof(float));\r\n",
      "\r\n",
      "\tmx_dist_cpu(A, B, m, n);\r\n",
      "\r\n",
      "\treturn B;\r\n",
      "}\r\n",
      "\r\n",
      "int main() \r\n",
      "{\r\n",
      "\r\n",
      "\tint m = _M, n = _N;\r\n",
      "\tfloat *A;\r\n",
      "\tA = (float*) malloc(m*n*sizeof(float));\r\n",
      "\tinit_mx(A, m, n);\r\n",
      "\r\n",
      "#if defined(CUDA) | defined(CHECK)\r\n",
      "\tfloat *gpu = run_cuda(A, m, n);\r\n",
      "#endif\r\n",
      "\r\n",
      "#if defined(CPU) | defined(CHECK)\r\n",
      "\tfloat *cpu = run_cpu(A, m, n);\r\n",
      "#endif\r\n",
      "\r\n",
      "#if defined(CHECK)\r\n",
      "\tcmp_mx(gpu, cpu, m, m);\r\n",
      "#endif\r\n",
      "\t//for(int _j = 0; _j < size; ++_j) printf(\"%f \", h_vec[2][_j]);\r\n",
      "\t// printf(\"\\n\");\r\n",
      "\r\n",
      "    \r\n",
      "    return 0;\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "%cat mm.cu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result And Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def compile(*defs, **defskw):\n",
    "    args = [f\"-D{k}\" for k in defs] + [f\"-D{k}={v}\" for k, v in defskw.items()]\n",
    "    _cmd = 'nvcc mm.cu -o mm'.split() + args\n",
    "    # print(' '.join(_cmd))\n",
    "    cmd = subprocess.run(_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "  \n",
    "    if(cmd.stdout): print('cmd.stdout', cmd.stdout)\n",
    "    if(cmd.stderr): print('cmd.stderr', cmd.stderr)\n",
    "    \n",
    "def run(env=None):\n",
    "    cmd = subprocess.run('./mm', stdout=subprocess.PIPE, stderr=subprocess.PIPE, env=env)\n",
    "    return cmd.stdout.decode('utf8')    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how the performance on CPU compares with the performace on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time on CPU\n",
      "\t1.2 s ± 371 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Execution time on GPU\n",
      "\t19.5 ms ± 394 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compile('CPU', _N=10_00, _M=50_0)\n",
    "print(\"Execution time on CPU\", end=\"\\n\\t\")\n",
    "%timeit run()\n",
    "print()\n",
    "\n",
    "compile('CUDA', _N=10_00, _M=50_0)\n",
    "print(\"Execution time on GPU\", end=\"\\n\\t\")\n",
    "%timeit run()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a clear gain of onGPU execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets analyze how the block size affects performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time with block size 8\n",
      "\t29.7 ms ± 698 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "Execution time with block size 16\n",
      "\t21.6 ms ± 2.95 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n",
      "Execution time with block size 32\n",
      "\t28.4 ms ± 1.82 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "Execution time with block size 64\n",
      "\t21.2 ms ± 3.38 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "Execution time with block size 128\n",
      "\t21.5 ms ± 2.84 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n",
      "Execution time with block size 256\n",
      "\t21.8 ms ± 2.64 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "Execution time with block size 512\n",
      "\t24.2 ms ± 1.79 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "Execution time with block size 1024\n",
      "\t22.2 ms ± 940 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "Execution time with block size 2048\n",
      "\t22.6 ms ± 3.02 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for bs in [8, 16, 32, 64, 128, 256, 512, 1024, 2048]:\n",
    "    compile('CUDA', _N=10_00, _M=50_0, BLOCK_SIZE=bs)\n",
    "    print(f\"Execution time with block size {bs}\", end=\"\\n\\t\")\n",
    "    %timeit run()\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this paper, we implemented an algorithm for calculating the degree of proximity of objects described by a set of numerically expressed properties using CUDA technology. Tests were performed for the kernel with global and shared memory.\n",
    "As a result of this work, the skill of working with CUDA technology of writing code for the GPU was obtained."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
