{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Цель лабораторной работы\n",
    "Целью данной работы является реализация алгоритма расчета степени близости объектов, описываемых набором численно выраженных свойств с использованием технологии CUDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Постановка задачи\n",
    "Мы имеем набор объектов, которые могут быть описаны наборами свойств, выраженных численно. В этой задаче необходимо рассчитать степень сходства объектов. В качестве входных параметров имеем матрицу:\n",
    "\n",
    "![](images/CropperScreenshot_2019-06-21_21:35:23.png)\n",
    "\n",
    "Надо вычислить расстояние между каждой возможной парой строк матрицы.\n",
    "\n",
    "![](images/CropperScreenshot_2019-06-21_21:35:41.png)\n",
    "\n",
    "В работе предполагается реализация данного алгоритма с использованием программно-аппаратной архитектуры параллельных вычислений CUDA с глобальной и общей памятью. Необходимо определить конфигурацию ядра и выполнить тесты ускорения с различными примерами входных параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Краткая Теория\n",
    "Технология CUDA вводит ряд дополнительных расширений для языка C, которые необходимы для написания кода для GPU:\n",
    "1. Функция указывает, как и откуда будут выполняться функции;\n",
    "2. Описатели переменных, которые служат для указания типа памяти, используемой графическим процессором;\n",
    "3. Квалификаторы запуска ядра GPU;\n",
    "4. Встроенные переменные для идентификации потоков, блоков и других параметров при выполнении кода в ядре GPU.\n",
    "5. Дополнительные типы переменных.\n",
    "\n",
    "\n",
    "Спецификаторы функций определяют, как и откуда будут вызываться функции. В CUDA есть 3 таких спецификатора:\n",
    "- __host__ \n",
    "- __global__ \n",
    "- __device__ \n",
    "\n",
    "\n",
    "Квалификаторы запуска ядра используются для описания количества блоков, потоков и памяти, которые необходимо выделить при вычислении на GPU. \n",
    "API хоста CUDA - это связь между процессором и графическим процессором.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритм реализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <cuda_runtime.h>\r\n",
      "\r\n",
      "#include <iostream>\r\n",
      "#include <memory>\r\n",
      "#include <string>\r\n",
      "\r\n",
      "#include <cuda.h>\r\n",
      "#include <stdio.h>\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "#ifndef BLOCK_SIZE\r\n",
      "# define BLOCK_SIZE 16\r\n",
      "#endif\r\n",
      "\r\n",
      "#ifndef _M\r\n",
      "# define _M 10000\r\n",
      "#endif\r\n",
      "\r\n",
      "#ifndef _N\r\n",
      "# define _N 10000\r\n",
      "#endif\r\n",
      "\r\n",
      "#if !defined(CUDA) && !defined(CPU) && !defined(CHECK)\r\n",
      "# define CUDA\r\n",
      "#endif\r\n",
      "\r\n",
      "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\r\n",
      "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\r\n",
      "{\r\n",
      "   if (code != cudaSuccess) \r\n",
      "   {\r\n",
      "      fprintf(stderr,\"gpuAssert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\r\n",
      "      if (abort) exit(code);\r\n",
      "   }\r\n",
      "}\r\n",
      "\r\n",
      "__global__ void mx_dist(float *m_in, float *m_out, int m, int n) \r\n",
      "{\r\n",
      "    int i = blockIdx.y * blockDim.y + threadIdx.y; \r\n",
      "    int j = blockIdx.x * blockDim.x + threadIdx.x;\r\n",
      "\tfloat s = 0, sum = 0;\r\n",
      "\r\n",
      "    if( i < m && j < m) {\r\n",
      "\r\n",
      "    \tfor(int k = 0; k < n; ++k) {\r\n",
      "    \t\ts = m_in[i*m + k] - m_in[j*m + k];\r\n",
      "    \t\tsum += s*s;\r\n",
      "    \t}\r\n",
      "\r\n",
      "    \t// printf(\"--> %d %d %f %f\\n\", j, i, m_in[j*n], sum);\r\n",
      "    \tm_out[i*m + j] = sum;\r\n",
      "    }\r\n",
      "}\r\n",
      "\r\n",
      "void mx_dist_cpu(float *m_in, float *m_out, int m, int n) \r\n",
      "{ \r\n",
      "\tfloat s, sum;\r\n",
      "    \r\n",
      "\tfor(int i = 0; i < m; ++i) \r\n",
      "\t\tfor(int j = 0; j < m; ++j) {\r\n",
      "\t\t\tsum = 0;\r\n",
      "\t\t\tfor(int k = 0; k < n; ++k) {\r\n",
      "\t\t\t\ts = m_in[i*m + k] - m_in[j*m + k];\r\n",
      "\t\t\t\tsum += s*s;\r\n",
      "\t\t\t}\r\n",
      "\t\t\tm_out[i*m + j] = sum;\r\n",
      "\t\t}\r\n",
      "}\r\n",
      "\r\n",
      "void init_mx(float *A, size_t m, size_t n) \r\n",
      "{\r\n",
      "\tfor(int i = 0; i < m; ++i) {\t\t\r\n",
      "\t\tfor(int j = 0; j < n; ++j) {\r\n",
      "\t\t\tfloat t = sin(i*m + j) * 10 + 1; \r\n",
      "\t\t\tA[i*m + j] = t;\r\n",
      "\t\t}\r\n",
      "\t}\r\n",
      "}\r\n",
      "void print_mx(float *A, size_t m, size_t n) \r\n",
      "{\r\n",
      "\tfor(int i = 0; i < m; ++i) {\t\t\r\n",
      "\t\tfor(int j = 0; j < n; ++j) {\r\n",
      "\t\t\tprintf(\"%d %d %f\\n\", i, j, A[i*m + j]);\t\t\t\r\n",
      "\t\t}\r\n",
      "\t}\r\n",
      "}\r\n",
      "\r\n",
      "void cmp_mx(float *A, float *B, size_t m, size_t n) \r\n",
      "{\r\n",
      "\tfor(int i = 0; i < m; ++i) {\t\t\r\n",
      "\t\tfor(int j = 0; j < n; ++j) {\r\n",
      "\t\t\tif( abs(A[i*m + j] - B[i*m + j]) > 0.01) {\r\n",
      "\t\t\t\tprintf(\"not equal %f %f\\n\", A[i*m + j], B[i*m + j]);\r\n",
      "\t\t\t\treturn;\r\n",
      "\t\t\t} else {\r\n",
      "\t\t\t\tprintf(\"Equal\\n\");\r\n",
      "\t\t\t}\r\n",
      "\t\t}\r\n",
      "\t}\r\n",
      "}\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "float *run_cuda(float *A, size_t m, size_t n) \r\n",
      "{\r\n",
      "\tcudaError_t e;\r\n",
      "\r\n",
      "\tfloat *A_d;\r\n",
      "\tfloat *B, *B_d;\r\n",
      "\r\n",
      "\tB = (float*) malloc(m*m*sizeof(float));\r\n",
      "\r\n",
      "\r\n",
      "\te = cudaMalloc(&A_d, m*n*sizeof(float));\r\n",
      "\tgpuErrchk(e);\r\n",
      "\te = cudaMalloc(&B_d, m*m*sizeof(float));\r\n",
      "\tgpuErrchk(e);\r\n",
      "\r\n",
      "\r\n",
      "\te = cudaMemcpy(A_d, A, m*n*sizeof(float), \r\n",
      "\t\t\t\tcudaMemcpyHostToDevice);\r\n",
      "\tgpuErrchk(e);\t\r\n",
      "\r\n",
      "\r\n",
      "    unsigned int grid_rows = (m + BLOCK_SIZE - 1) / BLOCK_SIZE;\r\n",
      "    unsigned int grid_cols = (n + BLOCK_SIZE - 1) / BLOCK_SIZE;\r\n",
      "\r\n",
      "    dim3 dimGrid(grid_cols, grid_rows);\r\n",
      "    dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\r\n",
      "\r\n",
      "\tmx_dist<<<dimGrid, dimBlock>>>(A_d, B_d, m, n);\r\n",
      "\r\n",
      "\r\n",
      "\te = cudaMemcpy(B, B_d, m*m*sizeof(float), \r\n",
      "\t\t\t\tcudaMemcpyDeviceToHost);\r\n",
      "\tgpuErrchk(e);\r\n",
      "\r\n",
      "\r\n",
      "\tcudaFree(A_d);\r\n",
      "\tcudaFree(B_d);\r\n",
      "\r\n",
      "\t\r\n",
      "\treturn B;\r\n",
      "}\r\n",
      "\r\n",
      "\r\n",
      "float *run_cpu(float *A, size_t m, size_t n) \r\n",
      "{    \r\n",
      "\t\r\n",
      "\tfloat *B;\r\n",
      "\tB = (float*) malloc(m*m*sizeof(float));\r\n",
      "\r\n",
      "\tmx_dist_cpu(A, B, m, n);\r\n",
      "\r\n",
      "\treturn B;\r\n",
      "}\r\n",
      "\r\n",
      "int main() \r\n",
      "{\r\n",
      "\r\n",
      "\tint m = _M, n = _N;\r\n",
      "\tfloat *A;\r\n",
      "\tA = (float*) malloc(m*n*sizeof(float));\r\n",
      "\tinit_mx(A, m, n);\r\n",
      "\r\n",
      "#if defined(CUDA) | defined(CHECK)\r\n",
      "\tfloat *gpu = run_cuda(A, m, n);\r\n",
      "#endif\r\n",
      "\r\n",
      "#if defined(CPU) | defined(CHECK)\r\n",
      "\tfloat *cpu = run_cpu(A, m, n);\r\n",
      "#endif\r\n",
      "\r\n",
      "#if defined(CHECK)\r\n",
      "\tcmp_mx(gpu, cpu, m, m);\r\n",
      "#endif\r\n",
      "\t//for(int _j = 0; _j < size; ++_j) printf(\"%f \", h_vec[2][_j]);\r\n",
      "\t// printf(\"\\n\");\r\n",
      "\r\n",
      "    \r\n",
      "    return 0;\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "%cat mm.cu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def compile(*defs, **defskw):\n",
    "    args = [f\"-D{k}\" for k in defs] + [f\"-D{k}={v}\" for k, v in defskw.items()]\n",
    "    _cmd = 'nvcc mm.cu -o mm'.split() + args\n",
    "    # print(' '.join(_cmd))\n",
    "    cmd = subprocess.run(_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "  \n",
    "    if(cmd.stdout): print('cmd.stdout', cmd.stdout)\n",
    "    if(cmd.stderr): print('cmd.stderr', cmd.stderr)\n",
    "    \n",
    "def run(env=None):\n",
    "    cmd = subprocess.run('./mm', stdout=subprocess.PIPE, stderr=subprocess.PIPE, env=env)\n",
    "    return cmd.stdout.decode('utf8')    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, как производительность на CPU сравнивается с производительностью на GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time on CPU\n",
      "\t1.2 s ± 371 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Execution time on GPU\n",
      "\t19.5 ms ± 394 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compile('CPU', _N=10_00, _M=50_0)\n",
    "print(\"Execution time on CPU\", end=\"\\n\\t\")\n",
    "%timeit run()\n",
    "print()\n",
    "\n",
    "compile('CUDA', _N=10_00, _M=50_0)\n",
    "print(\"Execution time on GPU\", end=\"\\n\\t\")\n",
    "%timeit run()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим явный выигрыш от выполнения GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, как размер блока влияет на производительность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time with block size 8\n",
      "\t29.7 ms ± 698 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "Execution time with block size 16\n",
      "\t21.6 ms ± 2.95 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n",
      "Execution time with block size 32\n",
      "\t28.4 ms ± 1.82 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "Execution time with block size 64\n",
      "\t21.2 ms ± 3.38 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "Execution time with block size 128\n",
      "\t21.5 ms ± 2.84 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n",
      "Execution time with block size 256\n",
      "\t21.8 ms ± 2.64 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "Execution time with block size 512\n",
      "\t24.2 ms ± 1.79 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "Execution time with block size 1024\n",
      "\t22.2 ms ± 940 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "Execution time with block size 2048\n",
      "\t22.6 ms ± 3.02 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for bs in [8, 16, 32, 64, 128, 256, 512, 1024, 2048]:\n",
    "    compile('CUDA', _N=10_00, _M=50_0, BLOCK_SIZE=bs)\n",
    "    print(f\"Execution time with block size {bs}\", end=\"\\n\\t\")\n",
    "    %timeit run()\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "\n",
    "В данной работе реализован алгоритм расчета степени близости объектов, описываемых набором численно выраженных свойств с использованием технологии CUDA. Тесты проводились для ядра с глобальной и общей памятью.\n",
    "В результате этой работы был получен навык работы с технологией CUDA написания кода для GPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
